{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-08-23T00:29:49.009928Z","iopub.status.busy":"2022-08-23T00:29:49.009407Z","iopub.status.idle":"2022-08-23T00:29:51.785417Z","shell.execute_reply":"2022-08-23T00:29:51.784137Z","shell.execute_reply.started":"2022-08-23T00:29:49.009823Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"]},{"data":{"text/html":["<style type='text/css'>\n",".datatable table.frame { margin-bottom: 0; }\n",".datatable table.frame thead { border-bottom: none; }\n",".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",".datatable .bool    { background: #DDDD99; }\n",".datatable .object  { background: #565656; }\n",".datatable .int     { background: #5D9E5D; }\n",".datatable .float   { background: #4040CC; }\n",".datatable .str     { background: #CC4040; }\n",".datatable .time    { background: #40CC40; }\n",".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",".datatable .frame tbody td { text-align: left; }\n",".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",".datatable th:nth-child(2) { padding-left: 12px; }\n",".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",".datatable .sp {  opacity: 0.25;}\n",".datatable .footer { font-size: 9px; }\n",".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n","</style>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["CPU times: user 1.49 s, sys: 456 ms, total: 1.95 s\n","Wall time: 2.74 s\n"]}],"source":["%%time\n","import datetime\n","import random\n","import gc\n","import warnings\n","from joblib import dump, load\n","import uuid\n","import pandas as pd\n","import numpy as np\n","from tqdm import tqdm\n","from sklearnex import patch_sklearn\n","patch_sklearn()\n","from xgboost import XGBClassifier, XGBRFClassifier\n","from sklearn.model_selection import train_test_split, GridSearchCV, KFold, StratifiedKFold\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, jaccard_score, recall_score, precision_score, accuracy_score, make_scorer, roc_auc_score, f1_score\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def convert_date_sort(frame : pd.DataFrame, primary_key : str, date_types : list = None):\n","        df = frame.copy()\n","        if date_types is not None :\n","            for date_col in date_types :\n","                df[date_col] = pd.to_datetime(df[date_col])\n","            df = df.sort_values([primary_key]+date_types)\n","        else :\n","            df = df.sort_values([primary_key])\n","        return df\n","\n","def feature_engineer_test(frame :pd.DataFrame, cat_features : list, primary_key : str):\n","        num_features = [x for x in list(frame.select_dtypes('number')) and x not in cat_features]\n","        test_num_agg = frame.groupby(primary_key)[num_features].agg(['first','mean', 'std', 'min', 'max', 'last'])\n","        test_num_agg.columns = ['_'.join(x) for x in test_num_agg.columns]\n","\n","        # Diff/Div columns\n","        for col in test_num_agg.columns:  \n","            # Last/First\n","            if 'last' in col and col.replace('last', 'first') in test_num_agg.columns:\n","                test_num_agg[col + '_life_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n","            if 'last' in col and col.replace('last', 'mean') in test_num_agg.columns:\n","                test_num_agg[col + '_lmean_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'mean')]\n","\n","        test_cat_agg = frame.groupby(primary_key)[cat_features].agg(['first', 'last', 'nunique'])\n","        test_cat_agg.columns = ['_'.join(x) for x in test_cat_agg.columns]\n","\n","        temp1 = frame.groupby([primary_key])['P_2'].count()\n","        temp1 = temp1.reset_index()\n","        temp1.columns = [primary_key,'num_statements']\n","        temp1 = temp1.set_index(primary_key)\n","\n","        df = pd.concat([test_num_agg, test_cat_agg,temp1], axis=1) #test_bal_agg  \n","        df = df.reset_index()\n","\n","        del test_num_agg, test_cat_agg, temp1\n","        gc.collect()\n","\n","        return df\n","    \n","def predictor(model, frame : pd.DataFrame) :\n","    #X = frame[frame.columns.tolist()[1:]].values\n","    X = frame.values\n","    pred_proba = model.predict_proba(X)[ : , 1]\n","    pred_class = model.predict(X)\n","    submission1  = pd.DataFrame({'customer_ID' : df[df.columns.tolist()[0]].values, 'prediction' : pred_proba})\n","    submission2  = pd.DataFrame({'customer_ID' : df[df.columns.tolist()[0]].values, 'prediction' : pred_class})\n","    del pred_proba, pred_class\n","    gc.collect()\n","    print('Predictions completed successfully ðŸ‘Œ')\n","    return [submission1, submission2]\n","\n","\n","def compute_scores(model , X_val) :\n","    pred = model.predict(X_val)\n","    pred_proba = model.predict_proba(X_val)[:,1]\n","    confusion = confusion_matrix(Y_val,pred.copy(), labels = model.classes_)\n","    \n","    scores = dict(acc = accuracy_score(Y_val,pred.copy()),\n","                      jaccard = jaccard_score(Y_val, pred.copy()), \n","                      recall = recall_score(Y_val, pred.copy()), \n","                      prec = precision_score(Y_val, pred.copy()), \n","                      auc = roc_auc_score(Y_val, pred_proba.copy()), \n","                      f1 = f1_score(Y_val, pred.copy()), \n","                      comp = amex_sk(Y_val,pred_proba), \n","                      tn = confusion[0,0]/sum(confusion[0]), \n","                      tp = confusion[1,1]/sum(confusion[1]))\n","    return scores\n","\n","\n","def amex_sk(target: np.ndarray, preds: np.ndarray) -> float:\n","    n_pos = np.sum(target)\n","    n_neg = target.shape[0] - n_pos\n","\n","    indices = np.argsort(preds)[::-1]\n","    preds, target = preds[indices], target[indices]\n","\n","    weight = 20.0 - target * 19.0\n","    cum_norm_weight = (weight * (1 / weight.sum())).cumsum()\n","    four_pct_mask = cum_norm_weight <= 0.04\n","    d = np.sum(target[four_pct_mask]) / n_pos\n","\n","    lorentz = (target * (1 / n_pos)).cumsum()\n","    gini = ((lorentz - cum_norm_weight) * weight).sum()\n","\n","    gini_max = 10 * n_neg * (1 - 19 / (n_pos + 20 * n_neg))\n","\n","    g = gini / gini_max\n","    return 0.5 * (g + d)\n","\n","\n","\n","def export_results(model, sub : list((pd.DataFrame,pd.DataFrame)) = None) :\n","    uid = str(uuid.uuid4())\n","    dump(model, '/kaggle/input/model_amex_'+uid+'joblib')\n","    if sub is not None :\n","        sub[0].to_csv('/kaggle/input/subimission_proba_amex_'+str(uid)+'.csv', index =False)\n","        sub[1].to_csv('/kaggle/input/subimission_class_amex_'+str(uid)+'.csv', index =False)\n","        print('Subimission completed successfully ðŸ‘Œ')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["os.chdir('/home/drxc/.kaggle/Kaggle_competitions/Datasets/Amex-Default-Prediction') # set the wd to /home/drxc/.kaggle/Kaggle_competitions/Datasets/Amex-Default-Prediction\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%%time\n","train_data = pd.read_parquet('train_data.parquet')\n","print(train_data.shape)\n","features = load('features.csv')\n","test_data = pd.read_parquet('test_data.parquet')\n","labels = pd.read_csv('train_labels.csv')\n","cat = ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68']"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%%time\n","data = pd.concat([train_data, test_data], ignore_index=True)\n","del train_data, test_data\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%%time\n","nacount = data.isna().any().count()/100\n","nullcols = nacount[nacount>= 30]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%%time\n","data = data.drop(columns = nullcols)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data = convert_date_sort(frame = data, primary_key = 'customer_ID', date_types = ['S_2'])\n","data = feature_engineer_test(frame = data, cat_features = cat, primary_key = 'customer_ID')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%%time\n","encoder = OrdinalEncoder(handle_unknown = 'use_encoded_value', unknown_value = np.nan)\n","scaler = MinMaxScaler()\n","\n","data[data.columns[1:]] = encoder.fit_transform(data[data.columns[1:]])\n","data[data.columns[1:]] = data[data.columns[1:]].fillna(data[data.columns[1:]].median())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%%time\n","train_data = pd.merge(data, labels, on = 'customer_ID', how = 'inner')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%%time\n","test_data = data.set_index('customer_ID').drop(index=labels.custom_ID.unique().tolist()).reset_index()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%%time\n","X_train, X_val, y_train, y_val = train_test_split(X = train_data[data.columns[1:-1]], y=train_data[data.columns[-1]] , test_size=0.1, random_state=43)\n","X_test = test_data[data.columns[1:]]\n","del train_data, data, test_data\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%%time\n","X_train = scaler.fit_transform(X_train)\n","X_val = scaler.transform(X_val)\n","X_test = scaler.transform(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%%time\n","xgb = XGBClassifier(base_score = 0.7, booster = 'gbtree', gamma = 10, \n","                    importance_type = 'weight', learning_rate = 0.1, max_leaves = 60, \n","                    n_jobs = -1, random_state = 43, reg_alpha = 0.3, \n","                    reg_lambda = 0.7,  subsample = 0.5, sampling_method= 'uniform', \n","                    verbosity = 3, tree_method = 'hist', objective  = 'reg:logistic', seed = 43)\n","\n","xgb = xgb.fit(X_train, y_train)\n","\n","scores = compute_scores(xgb , X_val)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%%time\n","sub = predictor(xgb, X_test)\n","export_results(xgb, sub = sub)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
